{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXzAL6yrDxQ4"
   },
   "source": [
    "## **Getting Started With Computer Vision Using TensorFlow Keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbMo9CJAD9Eg"
   },
   "source": [
    "Computer Vision attempts to perform the tasks that a human brain does with the aid of human eyes. Computer Vision is a branch of Deep Learning that deals with images and videos. Computer Vision tasks can be roughly classified into two categories:\n",
    "\n",
    "1. Discriminative tasks\n",
    "2. Generative tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSG_al4hEHuL"
   },
   "source": [
    "To read about it more, please refer [this](https://analyticsindiamag.com/computer-vision-using-tensorflow-keras/) article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2pcQBabEFyn"
   },
   "source": [
    "This session aims to give a strong foundation to Computer Vision by exploring image classification tasks using Convolutional Neural Networks built with TensorFlow Keras. More importance has been given to both the coding part and the key concepts of theory and math behind each operation. Let’s start our Computer Vision journey!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THvCUNOfEPkM"
   },
   "source": [
    "## **Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FgHYcSiyER-x"
   },
   "source": [
    "Import necessary packages, libraries and modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55Ns2OOREj-8"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_ifrNRNxxaF"
   },
   "source": [
    "\n",
    "We discuss Image Classification using TWO examples.\n",
    "1. Fashion MNIST dataset (`tf.keras.datasets`)\n",
    "2. Beans dataset (`tensorflow_datasets`)\n",
    "\n",
    "\n",
    "References:\n",
    "\n",
    "https://www.tensorflow.org/tutorials/images/cnn\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q --no-warn-script-location\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn tensorflow tensorflow_datasets keras opencv-python pillow scikit-image --user -q --no-warn-script-location\n",
    "\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qalA-4PPxjO3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5JLP76xyoP9"
   },
   "source": [
    "### Load Fashion MNIST data from Keras Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhGgvUDlyzgK"
   },
   "outputs": [],
   "source": [
    "fashion_data = keras.datasets.fashion_mnist.load_data()\n",
    "(x_train,y_train),(x_val,y_val)= fashion_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0TkNzX7ExAJ"
   },
   "source": [
    "Let’s have a look at the size of the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2HEFJeCzPCZ"
   },
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raTmnuIQE0bs"
   },
   "source": [
    "There are 60,000 grayscale images in the train data, each of size 28×28. For each image, the corresponding label is available in y_train. The official Datasets page informs that there are 10 different classes. The classes are numerically represented from 0 to 9. The images are low-clarity images of fashion collections such as shirts, coats, shoes, trousers, pullovers, and sandals.\n",
    "\n",
    "Similarly, we can have a look at the size of the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O_6HpmZMzZRv"
   },
   "outputs": [],
   "source": [
    "x_val.shape ,y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNI0Eh_uE3nt"
   },
   "source": [
    "There are 10,000 validation images and corresponding labels. Let’s sample an image and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D0C-ZTVhziGl"
   },
   "outputs": [],
   "source": [
    "plt.imshow(x_train[10])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buBVUmpjE56L"
   },
   "source": [
    "The values range from 0 to 255. We should scale the data by dividing the values by 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JnCI5Z25zyfN"
   },
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_val = x_val/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z-qu7FPqE8M5"
   },
   "source": [
    "We can visualize some 25 images and their corresponding class labels for a better understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEMkKY6V58HM"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "for i in range(1,26):\n",
    "  plt.subplot(5,5,i)\n",
    "  plt.imshow(x_train[i])\n",
    "  plt.title(y_train[i],color='r')\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "plt.tight_layout()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh1gyo2DFBPT"
   },
   "source": [
    "We can model a convolutional neural network to develop an image classifier. However, a convolution layer expects three dimensional data input. Usually, the shape of input images is (width, height, channels). Since we possess grayscale images, their shapes are of (width, height). We should increase the number of dimensions from 2 to 3 by expanding at the last axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HK16zief1noZ"
   },
   "outputs": [],
   "source": [
    "x_train = tf.expand_dims(x_train, axis=-1)\n",
    "x_val = tf.expand_dims(x_val, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXPZJYL7jUbK"
   },
   "source": [
    "Model building and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83Wggj6MFEZn"
   },
   "source": [
    "Let us build a Convolutional neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUmUikbMz72C"
   },
   "outputs": [],
   "source": [
    "classifier = keras.models.Sequential([# convolution layer\n",
    "                                      keras.layers.Conv2D(64,(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "                                      # flattening layer\n",
    "                                      keras.layers.Flatten(),\n",
    "                                      # dense hidden layer\n",
    "                                      keras.layers.Dense(128, activation='relu'),\n",
    "                                      # dense output layer\n",
    "                                      keras.layers.Dense(10,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n_2HTHml16PZ"
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjhKfKnYFLX4"
   },
   "source": [
    "We have built our convolutional neural network for our Computer Vision task. Here, we define an optimizer, a loss function and a metric required to train and evaluate the model. We use an Adam optimizer (a SGD variant), sparse categorical cross-entropy loss function (for multi-class classification) and accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1hhZUCW2C-z"
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',\n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INcgHDkWFNTs"
   },
   "source": [
    "Perform training for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYJ2PeqX2TFW"
   },
   "outputs": [],
   "source": [
    "history = classifier.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzy0lQqhjO7-"
   },
   "source": [
    "Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elE98W3NFQdC"
   },
   "source": [
    "Visualize losses and accuracies over epochs for both training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7ltXnr-6zYG"
   },
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "epochs = np.arange(1,11)\n",
    "plt.plot(epochs,hist['loss'], label='Train Loss')\n",
    "plt.plot(epochs,hist['val_loss'], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xticks(epochs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I08nFEftFTTw"
   },
   "source": [
    "The losses during training are going down, while that during evaluation is exploding. This is the direct cause of overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67Jopzgo7Ltr"
   },
   "outputs": [],
   "source": [
    "epochs = np.arange(1,11)\n",
    "plt.plot(epochs,hist['accuracy'], label='Train Accuracy')\n",
    "plt.plot(epochs,hist['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xticks(epochs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b01O8rYqFWDy"
   },
   "source": [
    "The accuracy plot confirms the insight provided by the losses plot. Steps against overfitting must be taken, such as implementing dropout layers, employing kernel regularizers, reducing model complexity, increasing the amount of data by augmentation and implementing early stopping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtXLcF-gEjI3"
   },
   "source": [
    "### Load BEANS dataset from TENSORFLOW_DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_lBrf9eFcEn"
   },
   "source": [
    "We explore more options and methodologies in Computer Vision with a relatively complex dataset. The Beans dataset available in-built with TensorFlow Datasets has images belonging to three classes.\n",
    "\n",
    "1. Healthy bean leaves\n",
    "2. Leaves with bean rust (unhealthy)\n",
    "3. Leaves with angular leaf spot (unhealthy)\n",
    "\n",
    "The major advantage of the TensorFlow Datasets is that the data is pre-processed and vectorized to enhance the off-the-shelf strategy. Load the beans dataset and its metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dLggI8_GDapC"
   },
   "outputs": [],
   "source": [
    "data, meta = tfds.load('beans',\n",
    "                 as_supervised=True,\n",
    "                 with_info=True,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GV9mIuUEPjyd"
   },
   "outputs": [],
   "source": [
    "train, val, test = data['train'], data['validation'], data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_t8QEwStc5zo"
   },
   "outputs": [],
   "source": [
    "ex = next(iter(test))\n",
    "ex[0].numpy()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkXjfjpDFmnF"
   },
   "source": [
    "The labels corresponding to three classes are provided as 0, 1 and 2. The corresponding readable label name can be extracted from the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vg0gHBlsSEqg"
   },
   "outputs": [],
   "source": [
    "label_extractor = meta.features['label'].int2str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wZ46u_UiFp-Q"
   },
   "source": [
    "Sample an image. Display its label and size, and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5apv3oEMEp8_"
   },
   "outputs": [],
   "source": [
    "for example,label in train.take(1):\n",
    "  print(label.numpy())\n",
    "  print(label_extractor(label))\n",
    "  print(example.shape)\n",
    "  plt.imshow(example)\n",
    "  plt.colorbar()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQg9V7bMFsRt"
   },
   "source": [
    "The images are of size 500 by 500 in three colour channels. The pixel values range from 0 to 255. Define a helper function to scale and resize the image to 160 by 160 (for memory efficiency). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgD4eklyaNyl"
   },
   "outputs": [],
   "source": [
    "def normalize(img, label):\n",
    "  img = tf.cast(img, tf.float32)\n",
    "  img = img/255.0\n",
    "  img = tf.image.resize(img,(160,160))\n",
    "  return img,label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVUZs_i7FuxJ"
   },
   "source": [
    "Scale pixel values and resize the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuJi0wl_asUl"
   },
   "outputs": [],
   "source": [
    "train = train.map(normalize)\n",
    "val = val.map(normalize)\n",
    "test = test.map(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2D22qbNea-9U"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "i = 1\n",
    "for example,label in train.skip(10).take(9):\n",
    "  plt.subplot(3,3,i)\n",
    "  plt.title(label_extractor(label),color='r')\n",
    "  plt.imshow(example)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  i += 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocb_4RfFFxUf"
   },
   "source": [
    "With some images, we humans can classify the leaves easily. Let’s check how far our model learns the same. Prepare the train and validation data in batches. Because Adam optimizer expects data to be in batches. Shuffle the train images, leaving validation and test images as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKQeEXC_l0SP"
   },
   "outputs": [],
   "source": [
    "train_batch = train.shuffle(1000).batch(64)\n",
    "val_batch = val.batch(64)\n",
    "test_batch = test.batch(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H62FRFYRjG21"
   },
   "source": [
    "Modeling and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSbGrcN_Fzn7"
   },
   "source": [
    "There will be two parts in a convolutional neural network: a base with convolutional layers and their associated layers, and a head with Dense layers and their associated layers. Build a convolutional neural network base with three Conv2D layers and two MaxPooling2D layers in between. While a convolution layer extracts features from the input image or feature map, a max pooling layer retains the important features discarding the less-important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OB6NcOn7cdxt"
   },
   "outputs": [],
   "source": [
    "base = keras.models.Sequential([\n",
    "                               keras.layers.Conv2D(64,(3,3), activation='relu',input_shape=[160,160,3]),\n",
    "                               keras.layers.MaxPooling2D((2,2)),\n",
    "                               keras.layers.Conv2D(128,(3,3),strides=2, activation='relu', kernel_regularizer='l1_l2'),\n",
    "                               keras.layers.MaxPooling2D((2,2)),\n",
    "                               keras.layers.Conv2D(128,(3,3),strides=2, activation='relu', kernel_regularizer='l1_l2'),                               \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r17dxzLeF1x2"
   },
   "source": [
    "Build a head with one Flatten layer, three Dense layers and one dropout layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkgGta5neliW"
   },
   "outputs": [],
   "source": [
    "head = keras.models.Sequential([\n",
    "                                keras.layers.Flatten(),\n",
    "                                keras.layers.Dense(128,activation='relu'),\n",
    "                                keras.layers.Dropout(0.5),\n",
    "                                keras.layers.Dense(64,activation='relu'),\n",
    "                                keras.layers.Dense(3,activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhHMIdXAF52Y"
   },
   "source": [
    "Stack base and head to form the complete architecture. It should be noted that the base and head can be constructed in a single Sequential model in one go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41R1ggT8e9IV"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([base,head])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsY7CBIr89rY"
   },
   "outputs": [],
   "source": [
    "base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hb-XDIP08_hd"
   },
   "outputs": [],
   "source": [
    "head.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvsplQSL9BMM"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0376pIDrF-RH"
   },
   "source": [
    "There are around 1.56 million parameters in our architecture. Let’s define our optimizer, loss function and metric to perform training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w2sJZtyFfmCh"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtBZW16LGAMW"
   },
   "source": [
    "Train the model for 40 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T_68h6m-gdE7"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_batch, validation_data=val_batch, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDD7P3yxjA1N"
   },
   "source": [
    "Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3QohvAMGDCw"
   },
   "source": [
    "Analyze the training performance using the training history. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hKlHNe6qU0J"
   },
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GULOiArFqgq5"
   },
   "outputs": [],
   "source": [
    "epochs = np.arange(6,41)\n",
    "plt.plot(epochs,hist['loss'][5:], label='Train Loss')\n",
    "plt.plot(epochs,hist['val_loss'][5:], label='Val Loss')\n",
    "plt.legend()\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xticks(np.arange(5,42,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uFR8sX6Xq5tZ"
   },
   "outputs": [],
   "source": [
    "epochs = np.arange(1,41)\n",
    "plt.plot(epochs,hist['accuracy'], label='Train Accuracy')\n",
    "plt.plot(epochs,hist['val_accuracy'], label='Val Accuracy')\n",
    "plt.legend()\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.xticks(np.arange(1,42,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLDav36KLVFV"
   },
   "outputs": [],
   "source": [
    "print(hist.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j710rnXOGHhD"
   },
   "source": [
    "Losses keep on reducing till the final epoch, and accuracies keep on increasing till the final epoch. It suggests that the model should be trained for more epochs until convergence. The curves are not smooth. It suggests implementing Batch Normalization that can provide a stable training experience. \n",
    "\n",
    "Finally, we deploy our model to predict our test data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BF4fQhCi8_z"
   },
   "source": [
    "Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COKI3_cHVzCH"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UxrhHhLWQP-"
   },
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4isHxN52XK2K"
   },
   "outputs": [],
   "source": [
    "images,labels = next(iter(test_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9l8TWBZGbibA"
   },
   "outputs": [],
   "source": [
    "p = images[0]\n",
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cg4wP6bHGK3U"
   },
   "source": [
    "Let’s evaluate the performance of prediction on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xlW5eBDnWbZd"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "batch = next(iter(test_batch))\n",
    "for i in range(9):\n",
    "  plt.subplot(3,3,i+1)\n",
    "  pred = np.argmax(preds[i])\n",
    "  plt.title(f'Actual: {label_extractor(labels[i])}' ,color='b',size=12)\n",
    "  if pred==labels[i]:\n",
    "    plt.xlabel(f'Predicted: {label_extractor(pred)}', color='b',size=12)\n",
    "  else:\n",
    "    plt.xlabel(f'Predicted: {label_extractor(pred)}', color='r',size=12)\n",
    "  plt.imshow(images[i])\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ERTxSYvi5zI"
   },
   "source": [
    "Actual labels are in the top of each image (blue in colour). Predicted labels are at the bottom of each image. Labels in blue and red colours refer to correct and incorrect predictions respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqDB1l9I6Br-"
   },
   "source": [
    "#**Related Articles:**\n",
    "\n",
    "> * [Getting Started with Computer Vision using Tensorflow Keras](https://analyticsindiamag.com/computer-vision-using-tensorflow-keras/)\n",
    "\n",
    "> * [Feature Extraction of Images with Skimage](https://analyticsindiamag.com/image-feature-extraction-using-scikit-image-a-hands-on-guide/)\n",
    "\n",
    "> * [Bitwise Operations On Images Using OpenCV](https://analyticsindiamag.com/how-to-implement-bitwise-operations-on-images-using-opencv/)\n",
    "\n",
    "> * [Face Swaping with OpenCV](https://analyticsindiamag.com/a-fun-project-on-building-a-face-swapping-application-with-opencv/)\n",
    "\n",
    "> * [Create Watermark Images with OpenCV](https://analyticsindiamag.com/how-to-create-a-watermark-on-images-using-opencv/)\n",
    "\n",
    "> * [Convert Image to Cartoon](https://analyticsindiamag.com/converting-an-image-to-a-cartoon/)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPLGrche4eV7Npgzw+7yqvU",
   "collapsed_sections": [],
   "name": "1_Getting_started_with_Computer_Vision.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
