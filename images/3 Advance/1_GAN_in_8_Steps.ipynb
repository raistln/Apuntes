{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OyQOyLSzUsuE"
   },
   "source": [
    "# **How To Build A GAN In 8 Simple Steps**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Affn9Nx2WXqd"
   },
   "source": [
    "We will follow the steps given below to build a simple Generative Adversarial Network.\n",
    "\n",
    "1. Importing the necessary modules\n",
    "2. Building a simple Generator network\n",
    "3. Building a simple Discriminator network\n",
    "4. Building a GAN by stacking the generator and discriminator\n",
    "5. Plotting the generated images\n",
    "6. A training method for GAN\n",
    "7. Loading and processing MNIST data\n",
    "8. Training The GAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rt82t1qi6qe8"
   },
   "source": [
    "## STEP 1.  Importing Necessary Modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q --no-warn-script-location\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn tensorflow keras opencv-python pillow scikit-image torch torchvision \\\n",
    "     tqdm --user -q --no-warn-script-location\n",
    "\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RBOf6szv6TAp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Input, BatchNormalization\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "from tqdm import tqdm\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k79wze966yaM"
   },
   "source": [
    "## STEP 2. Building A Simple Generator Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnSc2_Tn6xU7"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_generator():\n",
    "    #Initializing a neural network\n",
    "    generator = Sequential()\n",
    "    \n",
    "    #Adding an Input layer to the network\n",
    "    generator.add(Dense(units=256,input_dim=100))    \n",
    "\n",
    "    #Activating the layer with LeakyReLU activation function\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "\n",
    "    #Applying Batch Normalization \n",
    "    generator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "    #Adding a second layer\t\n",
    "    generator.add(Dense(units=512))\n",
    "    \n",
    "    #Adding a third layer\t\n",
    "    generator.add(Dense(units=1024))\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    #The output layer with 784(28x28) nodes\n",
    "    generator.add(Dense(units=784, activation='tanh'))\n",
    "    \n",
    "    #Compiling the Generator Network with loss and optimizer functions\n",
    "    generator.compile(loss='binary_crossentropy', optimizer= keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0QVshyu63wb"
   },
   "source": [
    "## STEP 3. Building A Simple Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0MubPU8962Xj"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_discriminator():\n",
    "    #Initializing a neural network\n",
    "    discriminator=Sequential()\n",
    "    \n",
    "    #Adding an Input layer to the network\n",
    "    discriminator.add(Dense(units=1024, input_dim=784))\n",
    "    \n",
    "    #Activating the layer with LeakyReLU activation function\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    #Adding a dropout layer to reduce overfitting\n",
    "    discriminator.add(Dropout(0.2))\n",
    "       \n",
    "    #Adding a second layer\n",
    "    discriminator.add(Dense(units=512))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "       \n",
    "    #Adding a third layer\t \n",
    "    discriminator.add(Dense(units=256))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "\n",
    "    #Adding a forth layer\n",
    "    discriminator.add(Dense(units=128))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    #Adding the output layer with sigmoid activation\n",
    "    discriminator.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    #Compiling the Discriminator Network with loss and optimizer functions\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer = keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "    \n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CuGNrkNBTr5"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*   **The above 2 code blocks simply define two different neural networks. The only major difference between the generator and the discriminator network are the inputs and outputs.**\n",
    "\n",
    "*   **The generator Network takes random noise as input and tries to recreate the images  from the training set using while the discriminator tries to distinguish the images generated by the generator Network from the actual training Set images.**\n",
    "\n",
    "*   **The discriminator is a binary classifier while the Generator generates an output similar to the actual images.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be4Al-1O7AkT"
   },
   "source": [
    "## STEP 4. Building A GAN Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Lv9oqNI6_Tc"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Stacking The Generator And Discriminator Networks To Form A GAN\n",
    "\n",
    "def gan_net(generator, discriminator):\n",
    "  \n",
    "    #Setting the trainable parameter of discriminator to False\n",
    "    discriminator.trainable=False\n",
    "    \n",
    "    #Instantiates a Keras tensor of shape 100 (Noise shape)\n",
    "    inp = Input(shape=(100,))\n",
    "    \n",
    "    #Feeds the input noise to the generator and stores the output in X\n",
    "    X = generator(inp)\n",
    "    \n",
    "    #Feeds the output from generator(X) to the discriminator and stores the result in out\n",
    "    out= discriminator(X)\n",
    "    \n",
    "    #Creates a model include all layers required in the computation of out given inp.\n",
    "    gan= Model(inputs=inp, outputs=out)\n",
    "    \n",
    "    #Compiling the GAN Network\n",
    "    gan.compile(loss='binary_crossentropy', optimizer = 'adam')\n",
    "    \n",
    "    return gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhaGnbXqQMOA"
   },
   "source": [
    "*   **The above method when invoked creates a GAN by stacking the generator and discriminator networks.**\n",
    "\n",
    "*   **The trainable parameter of the discriminator network when set to false freezes the weights in the discriminator network while the generator network is trained. This prevents the discriminator network from being updated while the generator generates new images from noise.**\n",
    "\n",
    "*   **The input shape to the GAN network is the shape of the noise. The noise is fed to the generator and its output is fed to the discriminator which classifies the image as original or generated.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzrZet7l7Koz"
   },
   "source": [
    "## STEP 5. Plotting The Generated Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H7Dlf6ON7I3u"
   },
   "outputs": [],
   "source": [
    "#Method to plot the images\n",
    "def plot_images(epoch, generator, dim = (10,10), figsize=(10,10)):\n",
    "    #Generate a normally distributed noise of shape(100x100)\n",
    "    noise= np.random.normal(loc=0, scale=1, size=[100, 100]) \n",
    "    #Generate an image for the input noise\n",
    "    generated_images = generator.predict(noise)\n",
    "    #Reshape the generated image \n",
    "    generated_images = generated_images.reshape(100,28,28)\n",
    "    \n",
    "    #Plot the image \n",
    "    plt.figure(figsize=figsize)\n",
    "   \n",
    "    #Plot for each pixel\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i],cmap='gray', interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRv-AcjJS7oX"
   },
   "source": [
    "**The above method generates plots for the images created by the generator from the normally distributed noise input.** \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jttWQDlJ7Q6j"
   },
   "source": [
    "## STEP 6. Method For Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeJVugKT7OpD"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Traing method with training set, default epoch and default batch_size as arguments.\n",
    "\n",
    "def train(X_train, epochs=5, batch_size=128):\n",
    "    \n",
    "    \n",
    "    #Initializing the GAN \n",
    "    generator= build_generator()\n",
    "    discriminator= build_discriminator()\n",
    "    gan = gan_net(generator,discriminator)\n",
    "    \n",
    "    \n",
    "    # Training the model for specified epochs\n",
    "    \n",
    "    for epoch in range(1,epochs+1 ):\n",
    "        print(\"###### @ Epoch \", epoch)\n",
    "        \n",
    "        #tqdm module helps to generate a status bar for training \n",
    "        for _ in tqdm(range(batch_size)):\n",
    "          \n",
    "            #Random noise with size batch_sizex100\n",
    "            noise= np.random.normal(0,1, [batch_size, 100])\n",
    "            \n",
    "            #Generating images from noise\n",
    "            generated_images = generator.predict(noise)\n",
    "            \n",
    "            #taking random images from the training set \n",
    "            image_batch =X_train[np.random.randint(low=0,high=X_train.shape[0],size=batch_size)]\n",
    "            \n",
    "            #Creating a new training set with real and fake images \n",
    "            X= np.concatenate([image_batch, generated_images])\n",
    "            \n",
    "            # Labels for generated and real data\n",
    "            y_dis=np.zeros(2*batch_size)  \n",
    "            y_dis[:batch_size]=1.0 # label for real images\n",
    "            \n",
    "            #Training the discriminator with real and generated images\n",
    "            discriminator.trainable=True\n",
    "            discriminator.train_on_batch(X, y_dis)\n",
    "            \n",
    "            #Labelling the generated images a sreal images(1) to trick the discriminator\n",
    "            noise= np.random.normal(0,1, [batch_size, 100])\n",
    "            y_gen = np.ones(batch_size)\n",
    "            \n",
    "            #Freezing the weights of the discriminator while training generator\n",
    "            discriminator.trainable=False\n",
    "            \n",
    "            #Training the gan network\n",
    "            gan.train_on_batch(noise, y_gen)\n",
    "        \n",
    "        #Plotting the images for every 10 epochs\n",
    "        #if epoch == 1 or epoch % 10 == 0:\n",
    "        plot_images(epoch,generator,dim = (10,10) , figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvQo31JB7VbV"
   },
   "source": [
    "## STEP 7.  Loading And Processing MNIST Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0mH5fw57Umc"
   },
   "outputs": [],
   "source": [
    "#Unpacking the training data from mnist data dataset\n",
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "#Converting to float type and normalizing the data\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "\n",
    "# convert shape of X_train from (60000, 28, 28) to (60000, 784) - 784 columns per row\n",
    "X_train = X_train.reshape(60000, 784)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phFIruBT7aEr"
   },
   "source": [
    "## STEP 8. Training The GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMTcbMB27ZY8"
   },
   "outputs": [],
   "source": [
    "train(X_train,epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFR7B3aTKAzr"
   },
   "source": [
    "**Thanks to Renu Khandelwal's [Generative Adversarial Network(GAN) using Keras](https://medium.com/datadriveninvestor/generative-adversarial-network-gan-using-keras-ce1c05cfdfd3)!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZtPNx78qe5T"
   },
   "source": [
    "#**Related Articles:**\n",
    "\n",
    "> * [GAN in simple 8 Steps](https://analyticsindiamag.com/how-to-build-a-generative-adversarial-network-in-8-simple-steps/)\n",
    "\n",
    "> * [PyTorch vs Keras vs Caffe](https://analyticsindiamag.com/keras-vs-pytorch-vs-caffe-comparing-the-implementation-of-cnn/)\n",
    "\n",
    "> * [Face Emotion Recognizer](https://analyticsindiamag.com/face-emotion-recognizer-in-6-lines-of-code/)\n",
    "\n",
    "> * [Sign Language Classification using CNN](https://analyticsindiamag.com/hands-on-guide-to-sign-language-classification-using-cnn/)\n",
    "\n",
    "> * [Transfer Learning for multi class classification](https://analyticsindiamag.com/transfer-learning-for-multi-class-image-classification-using-deep-convolutional-neural-network/)\n",
    "\n",
    "> * [FastAI with PyTorch for multiclass Image Classification](https://analyticsindiamag.com/fastai-with-tpu-in-pytorch-for-multiclass-image-classification/)\n",
    "\n",
    "> * [SuffleNet V1 for Multiclass Image Classification](https://analyticsindiamag.com/complete-guide-to-shufflenet-v1-with-implementation-in-multiclass-image-classification/)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOMOIy3n62ZpCXkPOGeoZuh",
   "collapsed_sections": [],
   "name": "1_GAN_in_8_Steps.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
