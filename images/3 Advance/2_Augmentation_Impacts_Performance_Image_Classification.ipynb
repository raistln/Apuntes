{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOdSz0vnr6tT"
   },
   "source": [
    "# **Augmentation Impacts Performance Of Image Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WPQwPwnsAFg"
   },
   "source": [
    "In this practice session, we are going to demonstrate how to do data augmentation to increase the size of the data. We will first build a deep learning model without performing augmentation and will compute the accuracy. After which we will build a similar deep learning model after performing augmentation and compute the accuracy. Finally, we will compare the performance of both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eJPzk1isFiK"
   },
   "source": [
    "## **The Dataset** \n",
    "\n",
    "We will use Fashion  MNIST data for this experiment. You can directly download the data from [Kaggle](https://www.kaggle.com/zalando-research/fashionmnist) or can load it the way shown in this article that is directly from Keras. This data set contains 28X28 images of different clothing as the respective label. There are a total of 60,000 images in the training and 10,000 images in the testing images. \n",
    "\n",
    "First, we will load the libraries and the dataset that is already divided into training and testing sets. Then we visualize the first 5 images in the training data set with their labels. Use the below code to the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q --no-warn-script-location\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim tensorflow keras \\\n",
    "    tqdm scikit-image pillow --user -q --no-warn-script-location\n",
    "\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3rOIotArvKj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i+1)\n",
    "    plt.imshow(X_test[i]) \n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('Labels: %s' % (y_test[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xE_EIqtTsNmi"
   },
   "source": [
    "We then normalize both pieces of training as well as testing data images and convert them into dimensions that are accepted by Keras. After that, we then convert labels to categorical values. Check the below code to do the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1F-BZD6IsPYz"
   },
   "outputs": [],
   "source": [
    "X_train=X_train.astype('float32')\n",
    "X_test=X_test.astype('float32')\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSxXU52AsRAF"
   },
   "source": [
    "## **Model without Data Augmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAtd6ceisTxQ"
   },
   "source": [
    "We first import the required libraries to build the model. Use the below code to define the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vx83A0MQsVR_"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDlmx3HVsW2I"
   },
   "source": [
    "We then define the model architecture with different convent layers followed by fully connected layers. Use the below code to define the model and then we will compile it. After compiling we fit the training data to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IcyNqAmZsZn0"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=32,epochs=10,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIQvk3Wrsf3r"
   },
   "outputs": [],
   "source": [
    "#We now check the testing accuracy of the model using the below code.\n",
    "print('Test accuracy:', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "he_Y7wdEsiBU"
   },
   "source": [
    "## **Model with Data Augmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhVjQ5FCsl5g"
   },
   "source": [
    "We will first generate data through data augmentation and visualize the new augmented data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAokDZNEsnsD"
   },
   "source": [
    "Follow the below code to do augmentation on the training image. We have just used rotation for generating the images whereas you generate images on the basis of other parameters as well given below. To do so you need to just change False to your desired value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rmhY1AIspzx"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  \n",
    "    samplewise_center=False, \n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,  \n",
    "    zca_whitening=False,\n",
    "    rotation_range=50,\n",
    "    width_shift_range=0.01, \n",
    "    height_shift_range=0.01, \n",
    "    horizontal_flip=False, \n",
    "    vertical_flip=False)\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "gen = datagen.flow(X_train[1:2], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(gen.next().squeeze())\n",
    "    plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xq9ISyBqsr_U"
   },
   "source": [
    "We will now fit the new training data to the model and start the training of the network again. Follow the below code to the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zGuQHfE4st1E"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=32,epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GrHnWc5Isv8Y"
   },
   "outputs": [],
   "source": [
    "print('Test accuracy:', model.evaluate(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZtPNx78qe5T"
   },
   "source": [
    "#**Related Articles:**\n",
    "\n",
    "> * [Image Classification Task with and without Data Augmentation](https://analyticsindiamag.com/image-data-augmentation-impacts-performance-of-image-classification-with-codes/)\n",
    "\n",
    "> * [Image Data Augmentation Work As A Regularizer](https://analyticsindiamag.com/why-does-image-data-augmentation-work-as-a-regularizer-in-deep-learning/)\n",
    "\n",
    "> * [Guide to Pillow](https://analyticsindiamag.com/hands-on-guide-to-pillow-python-library-for-image-processing/)\n",
    "\n",
    "> * [Guide to Pgmagick](https://analyticsindiamag.com/complete-guide-on-pgmagick-python-tool-for-image-processing/)\n",
    "\n",
    "> * [Guide to Mahotas](https://analyticsindiamag.com/complete-guide-to-mahotas-python-library-for-image-processing/)\n",
    "\n",
    "> * [Backgroung Tuning with Pixellib](https://analyticsindiamag.com/background-tuning-of-images-with-deeplab-v3-using-pixellib/)\n",
    "\n",
    "> * [Beginners Guide to Pytesseract](https://analyticsindiamag.com/beginners-guide-to-optical-character-recognition-using-pytesseract/)\n",
    "\n",
    "> * [Image to Image Translation](https://analyticsindiamag.com/hisd-python-implementation-of-image-to-image-translation/)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNSZg36bP/DoekA0DXnQyAk",
   "collapsed_sections": [],
   "name": "2_Augmentation_Impacts_Performance_Image_Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
