{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irrLJBeKEbdP"
   },
   "source": [
    "# **Albumentation â€“ Python Library for Image Augmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcRUu1CcEowG"
   },
   "source": [
    "The performance of a deep learning model is influenced by large datasets and diversity of the dataset. But, there might be situations where the dataset is simply not large enough or diverse enough. In such cases, data augmentation is used. Data augmentation is a technique that enables you to significantly increase the diversity of data available for training models, without actually collecting new data. Although deep learning models come with inbuilt methods to augment the data, these can be inefficient or lacking some required functionality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K23mdBKPEtQu"
   },
   "source": [
    "In this practice session, we will learn about an augmentation package for machine learning specifically using the PyTorch framework called Albumentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghEDFcu-EvXw"
   },
   "source": [
    "To read about Albumentation more, please refer [this](https://analyticsindiamag.com/hands-on-guide-to-albumentation/) article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cz6zvlnuE5uf"
   },
   "source": [
    "## **Hands-on implementation of albumentation transformations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nsf0V0A3E9Py"
   },
   "source": [
    "As mentioned earlier, this library gives a wide range of transformations other than the ones commonly used in other libraries. Let us see how we can implement these transformations on one image. \n",
    "\n",
    "Let us start with a single transformation. I have chosen a random image from google and will perform a horizontal flip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q --no-warn-script-location\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim tensorflow keras \\\n",
    "    tqdm scikit-image pillow albumentations --user -q --no-warn-script-location\n",
    "\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1330,
     "status": "ok",
     "timestamp": 1622710549000,
     "user": {
      "displayName": "Aishwarya Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64",
      "userId": "06108390091304498033"
     },
     "user_tz": -330
    },
    "id": "uMBpOpjdFeKn",
    "outputId": "f708a01a-2406-4426-9f28-8418396c19d7"
   },
   "outputs": [],
   "source": [
    "# !wget https://www.imperial.ac.uk/ImageCropToolT4/imageTool/uploaded-images/newseventsimage_1529346275459_mainnews2012_x1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 2345,
     "status": "ok",
     "timestamp": 1622710562321,
     "user": {
      "displayName": "Aishwarya Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64",
      "userId": "06108390091304498033"
     },
     "user_tz": -330
    },
    "id": "JAY2GqPZELlr",
    "outputId": "dfc17c34-3aa1-4a92-f81e-13273618065f"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "def view_transform(image):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "figure = cv2.imread('newseventsimage_1529346275459_mainnews2012_x1.jpg')\n",
    "figure = cv2.cvtColor(figure, cv2.COLOR_BGR2RGB)\n",
    "view_transform(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 1473,
     "status": "ok",
     "timestamp": 1622710602557,
     "user": {
      "displayName": "Aishwarya Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64",
      "userId": "06108390091304498033"
     },
     "user_tz": -330
    },
    "id": "rcVke8LEFrdc",
    "outputId": "4d6dedc7-fedb-4119-d635-7e9edb686d38"
   },
   "outputs": [],
   "source": [
    "transform = A.HorizontalFlip(p=0.5)\n",
    "random.seed(7)\n",
    "augmented_image = transform(image=figure)['image']\n",
    "view_transform(augmented_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVT7niDyFuNm"
   },
   "source": [
    "The real power of albumentation is in pipelining different transformations for the image at once. Let us implement this pipeline. I will pipeline \n",
    "\n",
    "> *  CLAHE: Contrast Limited Adaptive Histogram Equalization to equalize images\n",
    "> * Cutout: takes out a part of the image that is not very important for classification.\n",
    "> * Random rotate: rotates the image by a certain degree\n",
    "> * Blur: that reduces the intensity of pixels to appear blur\n",
    "> * Optical distortion: This distorts certain elements of the image.\n",
    "> * ShiftScaleRotate: Allows you to scale and rotate the image by certain angles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 1096,
     "status": "ok",
     "timestamp": 1622710641373,
     "user": {
      "displayName": "Aishwarya Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64",
      "userId": "06108390091304498033"
     },
     "user_tz": -330
    },
    "id": "CqwXdB-uF1XA",
    "outputId": "9e2cec5e-d318-4cd9-85b2-229af4769da4"
   },
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.CLAHE(),\n",
    "    A.RandomRotate90(),\n",
    "    A.Transpose(),\n",
    "    A.Cutout(num_holes=1, max_h_size=16,max_w_size = 16,p=1),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.50, rotate_limit=45, p=.75),\n",
    "    A.Blur(blur_limit=3),\n",
    "    A.OpticalDistortion(),\n",
    "])\n",
    "random.seed(42) \n",
    "augmented_image = transform(image=figure)['image']\n",
    "view_transform(augmented_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoX_494bF4Za"
   },
   "source": [
    "As you can see, all of these transformations are applied in a pipeline and in a really quick and efficient way. \n",
    "\n",
    "Another interesting feature of this is called the OneOf method. Here, the transformation defined in the OneOf block is assigned with probabilities. These are normalized and the transformation with the highest normalized value is selected and applied on the image. This way, there is more efficiency in applying suitable transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 1076,
     "status": "ok",
     "timestamp": 1622710663570,
     "user": {
      "displayName": "Aishwarya Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64",
      "userId": "06108390091304498033"
     },
     "user_tz": -330
    },
    "id": "gTeL8l5tF6rj",
    "outputId": "36515db4-cb67-48de-e632-deedc329bac3"
   },
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "        A.RandomRotate90(),\n",
    "        A.Flip(),\n",
    "        A.Transpose(),\n",
    "        A.OneOf([\n",
    "            A.MotionBlur(p=.2),\n",
    "            A.MedianBlur(blur_limit=3, p=0.3),\n",
    "            A.Blur(blur_limit=3, p=0.1),\n",
    "        ], p=0.2),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "        A.OneOf([\n",
    "            A.OpticalDistortion(p=0.3),\n",
    "            A.GridDistortion(p=.1),\n",
    "        ], p=0.2),\n",
    "        A.OneOf([\n",
    "            A.CLAHE(clip_limit=2),\n",
    "            A.RandomBrightnessContrast(),            \n",
    "        ], p=0.3),\n",
    "        A.HueSaturationValue(p=0.3),\n",
    "    ])\n",
    "random.seed(42) \n",
    "augmented_image = transform(image=figure)['image']\n",
    "view_transform(augmented_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcwv9ml8F97a"
   },
   "source": [
    "In this example above, the one of the method has motion blur, median blur and blur with assigned probabilities. Let us normalize this to see which has the highest probability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12k2IaPlGAe6"
   },
   "source": [
    "Motion blur = (0.2 )/(0.2+0.3+0.1) =0.3\n",
    "\n",
    "Median blur = (0.3)/(0.2+0.3+0.1)=0.5\n",
    "\n",
    "Blur = (0.1)/(0.2+0.3+0.1)=0.17\n",
    "\n",
    "The above calculations make it clear that the median blur will be applied. This way of pipelining increased the way the CPU is used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZtPNx78qe5T"
   },
   "source": [
    "#**Related Articles:**\n",
    "\n",
    "> * [Guide to Albumentation](https://analyticsindiamag.com/hands-on-guide-to-albumentation/)\n",
    "\n",
    "> * [Google STAC](https://analyticsindiamag.com/googles-stac-ssl-framework-for-object-detection/)\n",
    "\n",
    "> * [Point Transformers](https://analyticsindiamag.com/how-point-transformer-excels-in-3d-image-processing/)\n",
    "\n",
    "> * [Comparison of Transfer Learning with Multi Class Classification](https://analyticsindiamag.com/practical-comparison-of-transfer-learning-models-in-multi-class-image-classification/)\n",
    "\n",
    "> * [Fruit Recognition with CNN](https://analyticsindiamag.com/fruit-recognition-using-the-convolutional-neural-network/)\n",
    "\n",
    "> * [Semantic Segmentation Using TensorFlow Keras](https://analyticsindiamag.com/semantic-segmentation-using-tensorflow-keras/)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMQJcWsLqmmSS7X8sCzuf2A",
   "collapsed_sections": [],
   "name": "3_Albumentation_for_Image_Augmentation.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
