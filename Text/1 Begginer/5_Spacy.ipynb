{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkU85baK82Xi"
   },
   "source": [
    "# **Spacy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFao5q6n84ae"
   },
   "source": [
    "Spacy is an open-source software python library used in advanced natural language processing and machine learning. It will be used to build information extraction, natural language understanding systems, and to pre-process text for deep learning. It supports deep learning workflow in convolutional neural networks in parts-of-speech tagging, dependency parsing, and named entity recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kyb27idR9OKu"
   },
   "source": [
    "## **Installation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8yxBjqu9SoY"
   },
   "source": [
    "Scipy can be installed using setuptools and wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q --no-warn-script-location\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim --user -q --no-warn-script-location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 838
    },
    "executionInfo": {
     "elapsed": 15490,
     "status": "ok",
     "timestamp": 1621919925860,
     "user": {
      "displayName": "Aishwarya Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64",
      "userId": "06108390091304498033"
     },
     "user_tz": -330
    },
    "id": "8KiUmnT98mYH",
    "outputId": "5c94f2e5-f60d-497d-c704-cbce06998758"
   },
   "outputs": [],
   "source": [
    "!python -m pip install -U pip setuptools wheel --user -q --no-warn-script-location\n",
    "!python -m pip install spacy --user -q --no-warn-script-location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_pIICl79Y3S"
   },
   "source": [
    "## **SpaCy Models:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMwjJyv79bi4"
   },
   "source": [
    "To use spacy you are required to install the model using the pip command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7133,
     "status": "ok",
     "timestamp": 1621919934844,
     "user": {
      "displayName": "Aishwarya Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64",
      "userId": "06108390091304498033"
     },
     "user_tz": -330
    },
    "id": "qynp7z8S9XOS",
    "outputId": "baac4aeb-389d-4382-8584-97a20a81e606"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm --user -q --no-warn-script-location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1610,
     "status": "ok",
     "timestamp": 1621919942588,
     "user": {
      "displayName": "Aishwarya Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64",
      "userId": "06108390091304498033"
     },
     "user_tz": -330
    },
    "id": "IGGJBSrD9gVx",
    "outputId": "e432f541-b642-4acb-ab8f-ab5f1bb59948"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "# Print the document text\n",
    "print(doc.text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38Kaf39T9nOZ"
   },
   "source": [
    "## **Spacy Pipeline:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHkt6U_N9p4O"
   },
   "source": [
    "### **Tokenization:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hrhbm8Te9uib"
   },
   "source": [
    "Word tokens are the basic units of text involved in any NLP labeling task. The first step, when processing text, is to split it into tokens.\n",
    "\n",
    "Import the Spacy language class to create an NLP object of that class using the code shown in the following code. Then processing your doc using the NLP object and giving some text data or your text file in it to process it. Select the token you want to print and then print the output using the token and text function to get the value in text form.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1621925898656,
     "user": {
      "displayName": "Aishwarya Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64",
      "userId": "06108390091304498033"
     },
     "user_tz": -330
    },
    "id": "1GUOj5iK_aSe",
    "outputId": "5894ef35-2c0c-4482-8d7b-0110b369c6ca"
   },
   "outputs": [],
   "source": [
    "# Import the English language class and create the NLP object \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the text\n",
    "doc = nlp(\"I like tree kangaroos and narwhals.\")\n",
    "\n",
    "# Select the first token\n",
    "first_token = doc[0]\n",
    "\n",
    "# Print the first token's text\n",
    "print(first_token.text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGy9q2LA-Pat"
   },
   "source": [
    "### **Parts of speech tagging:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcTl6aS4UWyD"
   },
   "source": [
    "When we learn basic grammar, we understand the difference between nouns, verbs, adjectives, and adverbs, and although it may seem pointless at the time, it turns out to be a critical element of Natural Language Processing.\n",
    "\n",
    "Spacy provides convenient tools for breaking down sentences into lists of words and then categorizing each word with a specific part of speech based on the context.\n",
    "\n",
    "Here is the below code to get the P.O.S:\n",
    "\n",
    "Import the Spacy, and load model then process the text using nlp object now iterate over the loop to get the text->POS->dependency label as shown in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2087,
     "status": "ok",
     "timestamp": 1621925933266,
     "user": {
      "displayName": "Aishwarya Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64",
      "userId": "06108390091304498033"
     },
     "user_tz": -330
    },
    "id": "1WjqWuyI-Qxh",
    "outputId": "53427738-312a-4f77-8e4d-c99392dace56"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # This is for formatting only\n",
    "    print(f\"{token_text:<12}{token_pos:<10}{token_dep:<10}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qigQKJLIUdQG"
   },
   "source": [
    "### **Name Entity Detection:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "atKNHUSZUgWc"
   },
   "source": [
    "one of the most common labeling problems is finding entities in the text. Typically Name Entity detection constitutes the name of politicians, actors, and famous locations, and organizations, and products available in the market of that organization.\n",
    "\n",
    "Just import the spacy and load model and process the text using the nlp then iterate over every entity and print their label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2300,
     "status": "ok",
     "timestamp": 1621925974007,
     "user": {
      "displayName": "Aishwarya Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64",
      "userId": "06108390091304498033"
     },
     "user_tz": -330
    },
    "id": "_ibDt1JCUaSg",
    "outputId": "bda640b5-4c8c-4e27-85ef-47f0840bfaab"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "text = \"Upcoming iPhone X release date leaked as Apple reveals pre-orders\"\n",
    "# Process the text\n",
    "doc = nlp(text)\n",
    "# Iterate over the entities\n",
    "for ent in doc.ents:\n",
    "    # Print the entity text and label\n",
    "    print(ent.text, ent.label_)\n",
    "# Get the span for \"iPhone X\"\n",
    "iphone_x = doc[1:3]\n",
    "# Print the span text\n",
    "print(\"Missing entity:\", iphone_x.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFQl_9rlUmba"
   },
   "source": [
    "### **Dependency parsing:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzIx5hzFUqTH"
   },
   "source": [
    "The main concept of dependency parsing is that each linguistic unit (words) is connected by a directed link. These links are called dependencies in linguistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2120,
     "status": "ok",
     "timestamp": 1621927267331,
     "user": {
      "displayName": "Aishwarya Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64",
      "userId": "06108390091304498033"
     },
     "user_tz": -330
    },
    "id": "hK_DfCmTUkNO",
    "outputId": "4bf6da2f-a229-495b-ef65-feb65a283436"
   },
   "outputs": [],
   "source": [
    "#import the spacy and displacy to visualize the dependencies in each word.\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"This is a sentence.\")\n",
    "#displacy.serve(doc, style=\"dep\") \n",
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irjS-YR3UyIh"
   },
   "source": [
    "### **Matcher**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h9927uKIWaTb"
   },
   "source": [
    "The Matcher is very powerful and allows you to bootstrap a lot of NLP based tasks, such as entity extraction, finding the pattern matched in the text or document.\n",
    "\n",
    "Same as the above code, import the spacy, Matcher and initialize the matcher with the doc and define a pattern which you want to search in the doc. Then add the pattern to the matcher. Then print matches in the matcher docs.\n",
    "\n",
    "Look at the below code for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1084,
     "status": "ok",
     "timestamp": 1621927273399,
     "user": {
      "displayName": "Aishwarya Verma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiG6BREocxcd5R6rzlQGApoCsYso7BQAh63eXNz6Q=s64",
      "userId": "06108390091304498033"
     },
     "user_tz": -330
    },
    "id": "iv0h1qIvUv2I",
    "outputId": "661fdd38-0478-4dc5-e22a-2711b47d4da4"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Import the Matcher\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Upcoming iPhone X release date leaked as Apple reveals pre-orders\")\n",
    "# Initialize the Matcher with the shared vocabulary\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# Create a pattern matching two tokens: \"iPhone\" and \"X\"\n",
    "pattern = [{\"TEXT\": \"iPhone\"}, {\"TEXT\": \"X\"}]\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"IPHONE_X_PATTERN\", [pattern])\n",
    "# Use the matcher on the doc\n",
    "matches = matcher(doc)\n",
    "print(\"Matches:\", [doc[start:end].text for match_id, start, end in matches])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prpNOPgzWgiU"
   },
   "source": [
    "# **Read more articles on:**\n",
    "\n",
    "> * [Spacy Basics](https://analyticsindiamag.com/nlp-deep-learning-nlp-framework-nlp-model/)\n",
    "\n",
    "> * [StanfordCore NLP](https://analyticsindiamag.com/how-to-use-stanza-by-stanford-nlp-group-with-python-code/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM6iCdRanu/TKzYwpFrgOcg",
   "collapsed_sections": [],
   "name": "Spacy.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
