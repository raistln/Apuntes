{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"Sense2Vec.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyP8kTJU+b313UZlWeSVhoXK"},"kernelspec":{"name":"python3","display_name":"Python 3.8.8 64-bit ('base': conda)"},"language_info":{"name":"python","version":"3.8.8","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"}},"cells":[{"cell_type":"markdown","source":["# **Sense2vec**"],"metadata":{"id":"KKmbqJ_XsQJF"}},{"cell_type":"markdown","source":["Sense2vec is a neural network model that generates vector space representations of words from large corpora. It is an extension of the infamous word2vec algorithm.Sense2vec creates embeddings for ”senses” rather than tokens of words. A sense is a word combined with a label i.e. the information that represents the context in which the word is used. This label can be a POS Tag, Polarity, Entity Name, Dependency Tag etc."],"metadata":{"id":"PvVaC6wKsTvd"}},{"cell_type":"markdown","source":["To read about it more, please read [this](https://analyticsindiamag.com/guide-to-sense2vec-contextually-keyed-word-vectors-for-nlp/)."],"metadata":{"id":"kJhRXBEIsWWW"}},{"cell_type":"markdown","source":["##**Installing Dependencies**"],"metadata":{"id":"TyEtTNzeLAaT"}},{"cell_type":"markdown","source":["The sense2vec model from this package integrates with spacy seamlessly. Let’s play with this model."],"metadata":{"id":"Fg9wvyXZuwrK"}},{"cell_type":"code","execution_count":2,"source":["!python -m pip install pip --upgrade --user -q --no-warn-script-location\n","!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim --user -q --no-warn-script-location"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["!python -m pip install spacy --user -q\n","!python -m pip install sense2vec --user -q\n","!python -m spacy download en_core_web_sm --user -q"],"outputs":[{"output_type":"stream","name":"stdout","text":["2021-10-28 14:19:02.460800: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n","2021-10-28 14:19:02.460864: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n"]}],"metadata":{"id":"0OwpVcVKHzsW"}},{"cell_type":"code","execution_count":null,"source":["!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz"],"outputs":[],"metadata":{"id":"hiL5pZ5vH_HM"}},{"cell_type":"code","execution_count":null,"source":["!tar -xzvf s2v_reddit_2015_md.tar.gz"],"outputs":[],"metadata":{"id":"dUk4panLIsqC"}},{"cell_type":"code","execution_count":null,"source":["import IPython\n","IPython.Application.instance().kernel.do_shutdown(True)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["#Standalone Usage"],"metadata":{"id":"pdfuQchcLK0m"}},{"cell_type":"markdown","source":["Getting started with this package is extremely easy. Standalone usage is as follows"],"metadata":{"id":"Jl79WQSUwBGJ"}},{"cell_type":"markdown","source":["We can get the embeddings of a sense i.e word along with labels by using “token +’|’+label” as a key."],"metadata":{"id":"QaKl-8DTwJOM"}},{"cell_type":"code","execution_count":6,"source":["from sense2vec import Sense2Vec\n","s2v = Sense2Vec().from_disk(\"https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/blob/main/sense2vec/_s2v_old/\")\n","query = \"apple|NOUN\"\n","assert query in s2v\n","vector = s2v[query]\n","vector.shape"],"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Can't read file: https:/gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/blob/main/sense2vec/_s2v_old/cfg","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-43bdb6ee33d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msense2vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSense2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSense2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/blob/main/sense2vec/_s2v_old/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"apple|NOUN\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms2v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2v\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/sense2vec/sense2vec.py\u001b[0m in \u001b[0;36mfrom_disk\u001b[0;34m(self, path, exclude)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mcache_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"cache\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrsly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"cfg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfreqs_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrsly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreqs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/srsly/_json_api.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mujson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforce_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mujson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.local/lib/python3.8/site-packages/srsly/util.py\u001b[0m in \u001b[0;36mforce_path\u001b[0;34m(location, require_exists)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_exists\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Can't read file: {location}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Can't read file: https:/gitlab.com/AnalyticsIndiaMagazine/practicedatasets/-/blob/main/sense2vec/_s2v_old/cfg"]}],"metadata":{"id":"PYelGLR0OGkS"}},{"cell_type":"markdown","source":[],"metadata":{"id":"ekb1uSVqwHNo"}},{"cell_type":"code","execution_count":null,"source":["s2v.most_similar('apple|NOUN')"],"outputs":[],"metadata":{"id":"KRd5uFk9OHxl"}},{"cell_type":"code","execution_count":null,"source":["s2v.most_similar('Apple|ORG')"],"outputs":[],"metadata":{"id":"dory2mrqOK8f"}},{"cell_type":"markdown","source":["The difference between a king and a man when added to a woman is very close to a woman. These vectors capture the semantic information well. This is not surprising as even word2vec models these relationships. Let’s look at the most similar senses for polysemic words."],"metadata":{"id":"4HH9SmkwwVkg"}},{"cell_type":"code","execution_count":null,"source":["import numpy as np\n","x=s2v['king|NOUN']-s2v['man|NOUN']+s2v['woman|NOUN']\n","y=s2v['queen|NOUN']\n","def cosine_similarity(x,y):\n","    root_x=np.sqrt(sum([i**2 for i in x]))\n","    root_y=np.sqrt(sum([i**2 for i in y]))\n","    return sum([i*j for i,j in zip(x,y)])/root_x/root_y\n","cosine_similarity(x,y)"],"outputs":[],"metadata":{"id":"O0W2BGijONtq"}},{"cell_type":"code","execution_count":null,"source":["from collections import Counter\n","import matplotlib.pyplot as plt\n","grams=[len(i.split('_')) for i in s2v.keys()]\n","c=Counter(grams)\n","c=sorted(c.items())\n","c=list(zip(*c))\n","plt.plot(c[1])\n","plt.xlabel('Token Length')\n","plt.ylabel('Frequency')\n","plt.show()"],"outputs":[],"metadata":{"id":"gLuBfUx2OQxa"}},{"cell_type":"markdown","source":["## **Usage as a spacy component**"],"metadata":{"id":"OrFDxbeRLoi7"}},{"cell_type":"markdown","source":["Polysemic words sense disambiguation\n","\n","These embeddings captured the context very well. But it is the responsibility of the user of these embeddings to provide a label along with a token to select the right vector."],"metadata":{"id":"t2t9BKQ3ww4r"}},{"cell_type":"markdown","source":["Sense2vec package can infer these labels when provided with spacy’s document object. Following is an example of this kind of usage."],"metadata":{"id":"8Lv2UM2GwzrB"}},{"cell_type":"code","execution_count":null,"source":["import spacy\n","\n","nlp = spacy.load(\"en_core_web_sm\")\n","s2v = nlp.add_pipe(\"sense2vec\")\n","s2v.from_disk(\"s2v_old/\")\n"],"outputs":[],"metadata":{"id":"8cxzd8vgJdq_"}},{"cell_type":"markdown","source":["Sense2vec can be added as a component to the spacy pipeline. We can initialize this model with random values and train it or we can load a pre-trained model and update it according to our needs."],"metadata":{"id":"VDn-c7ZYw2Zj"}},{"cell_type":"code","execution_count":null,"source":["doc = nlp('Power resides where men believe it resides. It’s a trick, a shadow on the wall.')\n","doc._.s2v_phrases"],"outputs":[],"metadata":{"id":"uMfJ907FJdof"}},{"cell_type":"code","execution_count":null,"source":["doc[-2]._.s2v_most_similar(3)"],"outputs":[],"metadata":{"id":"7fL94qPyJdl3"}},{"cell_type":"markdown","source":["That’s it, we can get embeddings, similar phrases e.t.c for all the supported phrases from this document.\n","\n","The spacy pipeline has a pos tagger and named entity recognizer components before the sense2vec component.Sense2vec component uses results from these components to create word senses."],"metadata":{"id":"dKFQVXEpw74P"}},{"cell_type":"code","execution_count":null,"source":["for i in doc:\n","  try:\n","    print(i,i.pos_,'\\n',i._.s2v_most_similar(3))\n","  except ValueError as e:\n","    #If a token pos tag combination is not in the keyed vectors it raises Error so we need to catch it\n","    pass"],"outputs":[],"metadata":{"id":"H3-wr5dLJdjS"}},{"cell_type":"markdown","source":["## **Loading Data**"],"metadata":{"id":"9qnE6VCRLw7q"}},{"cell_type":"code","execution_count":null,"source":["def get_subjects(x):\n","  subjects=[]\n","  with open(x,'r') as f:\n","      for line in f.readlines():\n","          if line.startswith('Subject:'):\n","              line=line.replace('Subject:',' ')\n","              line=line.replace('Re:',' ')\n","              line=line.strip()\n","              if len(line)<15:\n","                  continue\n","              subjects.append(line)\n","  return list(set(subjects))"],"outputs":[],"metadata":{"id":"zKyCseyBJdeA"}},{"cell_type":"code","execution_count":null,"source":["mideast_subjects=get_subjects('talk.politics.mideast.txt')\n","gun_subjects=get_subjects('talk.politics.guns.txt')"],"outputs":[],"metadata":{"id":"p18wuXORJdSQ"}},{"cell_type":"code","execution_count":null,"source":["import pandas as pd\n","df=pd.DataFrame(mideast_subjects+gun_subjects,columns=['subjects'])\n","df['topic']=['mideast']*len(mideast_subjects)+['guns']*len(gun_subjects)\n","print(df.shape)\n","df['topic'].value_counts()"],"outputs":[],"metadata":{"id":"LiLXcPbZSKJr"}},{"cell_type":"markdown","source":["## **Generating Word2vec embeddings**"],"metadata":{"id":"LH4YoGELL4Pn"}},{"cell_type":"code","execution_count":null,"source":["import gensim\n","from tqdm import tqdm\n","model = gensim.models.Word2Vec(df['subjects'], min_count=1,size=128,workers=4)\n","X_s=[]\n","random_vectors=dict()\n","for i in tqdm(df['subjects'].values):\n","  doc=nlp(i)\n","  x=np.zeros(128)\n","  for j in doc:\n","      try:\n","        random_vectors[j.text.lower()]=model[j.text.lower()]\n","      except:\n","        random_vectors[j.text.lower()]=np.random.rand(128)\n","      x+=random_vectors[j.text.lower()]\n","  X_s.append(x)\n","y=df['topic'].values"],"outputs":[],"metadata":{"id":"acTuf3sXhcyf"}},{"cell_type":"code","execution_count":null,"source":["random_vectors.keys()"],"outputs":[],"metadata":{"id":"r7ErFUOVj89T"}},{"cell_type":"markdown","source":["## **Generating Sense2vec Embeddings**"],"metadata":{"id":"wyV1hpZ2L-SM"}},{"cell_type":"code","execution_count":null,"source":["from tqdm import tqdm_notebook as tqdm\n","import numpy as np\n","X=[]\n","for i in tqdm(df['subjects'].values):\n","  doc=nlp(i)\n","  x=np.zeros(128)\n","  for i in doc:\n","    try:\n","      x+=i._.s2v_vec\n","    except (ValueError,TypeError,KeyError) as e:\n","      x+=random_vectors[i.text.lower()]\n","      # sense=i.text+'|'+i.pos_\n","      # try:\n","      #   x+=random_vectors[sense]\n","      # except:\n","      #   random_vectors[sense]=np.random.rand(128)\n","      #   x+=random_vectors[sense]\n","  X.append(x)\n","y=df['topic'].values"],"outputs":[],"metadata":{"id":"Pvq-kF8nVPNz"}},{"cell_type":"code","execution_count":null,"source":["X_s=np.array(X_s)\n","X=np.array(X)\n","X_s.shape,X.shape,y.shape"],"outputs":[],"metadata":{"id":"MktZdNw3ZLZZ"}},{"cell_type":"markdown","source":["## **Simple DNN model**"],"metadata":{"id":"NcpVrtRtN1dn"}},{"cell_type":"code","execution_count":null,"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers.normalization import BatchNormalization\n","import tensorflow as tf\n","model=Sequential()\n","\n","model.add(Dense(64,input_dim=128,activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(32,activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(1,activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer= tf.keras.optimizers.Adam(),\n","              metrics=['accuracy'])\n","\n","model.summary()"],"outputs":[],"metadata":{"id":"lnfrZXxlSYKD"}},{"cell_type":"code","execution_count":null,"source":["class_map={'mideast':0,'guns':1}\n","Y=np.array(list(map(lambda x:class_map[x],y)))\n","history=model.fit(X, Y, epochs=30, batch_size=16,validation_split=0.2)"],"outputs":[],"metadata":{"id":"HrfykI7AUZ5Q"}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.pyplot as plt\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.show()"],"outputs":[],"metadata":{"id":"0DBma5JtVLdb"}},{"cell_type":"code","execution_count":null,"source":["plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.show()"],"outputs":[],"metadata":{"id":"6mE0wJEWac9e"}},{"cell_type":"code","execution_count":null,"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers.normalization import BatchNormalization\n","import tensorflow as tf\n","model=Sequential()\n","\n","model.add(Dense(64,input_dim=128,activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(32,activation='relu'))\n","model.add(BatchNormalization())\n","model.add(Dense(1,activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer= tf.keras.optimizers.Adam(),\n","              metrics=['accuracy'])\n","\n","model.summary()"],"outputs":[],"metadata":{"id":"D6z8qM8BdKxg"}},{"cell_type":"code","execution_count":null,"source":["class_map={'mideast':0,'guns':1}\n","Y=np.array(list(map(lambda x:class_map[x],y)))\n","history_s=model.fit(X_s, Y, epochs=30, batch_size=16,validation_split=0.2)"],"outputs":[],"metadata":{"id":"94xSzJ1Kgjgn"}},{"cell_type":"code","execution_count":null,"source":["plt.plot(history_s.history['loss'])\n","plt.plot(history_s.history['val_loss'])\n","plt.show()"],"outputs":[],"metadata":{"id":"FKqSDtTogpC-"}},{"cell_type":"code","execution_count":null,"source":["import matplotlib.pyplot as plt\n","import matplotlib\n","font = {'family' : 'normal',\n","        'size'   : 22}\n","plt.tight_layout()\n","matplotlib.rc('font', **font)\n","plt.figure(figsize=(15,8))\n","plt.plot(history_s.history['accuracy'],label='word2vec_train')\n","plt.plot(history_s.history['val_accuracy'],label='word2vec_validation')\n","plt.plot(history.history['accuracy'],label='sense2vec_train')\n","plt.plot(history.history['val_accuracy'],label='sense2vec_validation')\n","plt.legend(bbox_to_anchor=(0.7, 0.7))\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.savefig('foo.png')\n","plt.show()"],"outputs":[],"metadata":{"id":"m7qEM3B_gwdO"}},{"cell_type":"markdown","source":["# **Related Articles:**\n","\n","> * [Guide to Sense2vec](https://analyticsindiamag.com/guide-to-sense2vec-contextually-keyed-word-vectors-for-nlp/)\n","\n","> * [Download Twitter Data and Analyze](https://analyticsindiamag.com/hands-on-guide-to-download-analyze-and-visualize-twitter-data/)\n","\n","> * [Sentiment Analysis using LSTM](https://analyticsindiamag.com/how-to-implement-lstm-rnn-network-for-sentiment-analysis/)\n","\n","> * [VADER Sentiment Analysis](https://analyticsindiamag.com/sentiment-analysis-made-easy-using-vader/)\n","\n","> * [Polyglot](https://analyticsindiamag.com/hands-on-tutorial-on-polyglot-python-toolkit-for-multilingual-nlp-applications/)\n","\n","> * [Textblob](https://analyticsindiamag.com/lets-learn-textblob-quickstart-a-python-library-for-processing-textual-data/)\n"],"metadata":{"id":"prpNOPgzWgiU"}}]}