{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1lfTrzvgzSkR"
   },
   "source": [
    "# **RNN for Text Generation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iplAOofezVWt"
   },
   "source": [
    "In this session, we will train a Recurrent Neural Network (RNN) in PyTorch on the names belonging to several languages. After successful training, the RNN model will predict names belonging to a language that start with an input alphabet letter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYlnuJjHzXpH"
   },
   "source": [
    "## **Implementation in PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjRNVRzG1Hiu"
   },
   "source": [
    "Now, we will import all the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q --no-warn-script-location\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn torch nltk gensim --user -q --no-warn-script-location\n",
    "\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDvJiZf3xD5a"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94O75vlC1gHF"
   },
   "source": [
    "The below code snippet will read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-58ydTqnct_C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-10-28 12:52:33--  https://download.pytorch.org/tutorial/data.zip\n",
      "Resolving download.pytorch.org (download.pytorch.org)... 18.66.78.69, 18.66.78.33, 18.66.78.3, ...\n",
      "Connecting to download.pytorch.org (download.pytorch.org)|18.66.78.69|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2882130 (2.7M) [application/zip]\n",
      "Saving to: ‘data.zip’\n",
      "\n",
      "data.zip            100%[===================>]   2.75M  3.85MB/s    in 0.7s    \n",
      "\n",
      "2021-10-28 12:52:35 (3.85 MB/s) - ‘data.zip’ saved [2882130/2882130]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://download.pytorch.org/tutorial/data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qu8_JDI51kQU"
   },
   "outputs": [],
   "source": [
    "all_let = string.ascii_letters + \" .,;'-\"\n",
    "n_let = len(all_let) + 1\n",
    "\n",
    "def getFiles(path):\n",
    "  return glob.glob(path)\n",
    "\n",
    "# Unicode string to ASCII\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_let\n",
    "    )\n",
    "\n",
    "# Read a file and split into lines\n",
    "def getLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "# Build the cat_lin dictionary, a list of lines per category\n",
    "cat_lin = {}\n",
    "all_ctg = []\n",
    "for filename in getFiles('data/names/*.txt'):\n",
    "    categ = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_ctg.append(categ)\n",
    "    lines = getLines(filename)\n",
    "    cat_lin[categ] = lines\n",
    "\n",
    "n_ctg = len(all_ctg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-OVRJBu24z6"
   },
   "source": [
    "In the next step, we will define the module class to generate the names. The module will be a recurrent neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3IKQdZAo27St"
   },
   "outputs": [],
   "source": [
    "class NameGeneratorModule(nn.Module):\n",
    "  def __init__(self, inp_size, hid_size, op_size):\n",
    "      super(NameGeneratorModule, self).__init__()\n",
    "      self.hid_size = hid_size\n",
    "\n",
    "      self.i2h = nn.Linear(n_ctg + inp_size + hid_size, hid_size)\n",
    "      self.i2o = nn.Linear(n_ctg + inp_size + hid_size, op_size)\n",
    "      self.o2o = nn.Linear(hid_size + op_size, op_size)\n",
    "      \n",
    "      self.dropout = nn.Dropout(0.1)\n",
    "      self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "  def forward(self, category, input, hidden):\n",
    "      inp_comb = torch.cat((category, input, hidden), 1)\n",
    "      hidden = self.i2h(inp_comb)\n",
    "      output = self.i2o(inp_comb)\n",
    "      op_comb = torch.cat((hidden, output), 1)\n",
    "      output = self.o2o(op_comb)\n",
    "      output = self.dropout(output)\n",
    "      output = self.softmax(output)\n",
    "      return output, hidden\n",
    "\n",
    "  def initHidden(self):\n",
    "      return torch.zeros(1, self.hid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yh0CD8W729x9"
   },
   "source": [
    "The below functions will be used to pick the random item from a list and a random line from a category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZDqKmHF2_yg"
   },
   "outputs": [],
   "source": [
    "def randChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randTrainPair():\n",
    "    category = randChoice(all_ctg)\n",
    "    line = randChoice(cat_lin[category])\n",
    "    return category, line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a8dvY_RZ3Cpt"
   },
   "source": [
    "The below functions will convert the data to the compatible format for the RNN module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qcCkso-i3FEZ"
   },
   "outputs": [],
   "source": [
    "def categ_Tensor(categ):\n",
    "    li = all_ctg.index(categ)\n",
    "    tensor = torch.zeros(1, n_ctg)\n",
    "    tensor[0][li] = 1\n",
    "    return tensor\n",
    "\n",
    "def inp_Tensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_let)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "        tensor[li][0][all_let.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def tgt_Tensor(line):\n",
    "    letter_indexes = [all_let.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_let - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xV9e_7Y3Hfr"
   },
   "source": [
    "The below function will create random training examples including category, input and target tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9Ugzz3m3Jov"
   },
   "outputs": [],
   "source": [
    "def rand_train_exp():\n",
    "    category, line = randTrainPair()\n",
    "    category_tensor = categ_Tensor(category)\n",
    "    input_line_tensor = inp_Tensor(line)\n",
    "    target_line_tensor = tgt_Tensor(line)\n",
    "    return category_tensor, input_line_tensor, target_line_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfqATDji3LiP"
   },
   "source": [
    "The below function will define the loss criteria for the RNN module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QE4E3RWO3OQ8"
   },
   "outputs": [],
   "source": [
    "#Loss\n",
    "criterion = nn.NLLLoss()\n",
    "#Learning rate\n",
    "lr_rate = 0.0005\n",
    "\n",
    "def train(category_tensor, input_line_tensor, target_line_tensor):\n",
    "    target_line_tensor.unsqueeze_(-1)\n",
    "    hidden = model.initHidden()\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_line_tensor.size(0)):\n",
    "        output, hidden = model(category_tensor, input_line_tensor[i], hidden)\n",
    "        l = criterion(output, target_line_tensor[i])\n",
    "        loss += l\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    for p in model.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-lr_rate)\n",
    "\n",
    "    return output, loss.item() / input_line_tensor.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujDrsS1I3V3L"
   },
   "source": [
    "To show time during training, the bellow function is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUuHmRoj3Xw8"
   },
   "outputs": [],
   "source": [
    "def time_taken(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgihdZfc3juI"
   },
   "source": [
    "In the next step, we will define our RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFMkpqwC3lZ8"
   },
   "outputs": [],
   "source": [
    "model = NameGeneratorModule(n_let, 128, n_let)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uySSghZB3v1q"
   },
   "source": [
    "We will see the parameters of the defined RNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HG3fjGY93x6j"
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pK8H8Y2qGRcV"
   },
   "outputs": [],
   "source": [
    "def rand_train_exp():\n",
    "    category, line = randTrainPair()\n",
    "    category_tensor = categ_Tensor(category)\n",
    "    input_line_tensor = inp_Tensor(line)\n",
    "    target_line_tensor = tgt_Tensor(line)\n",
    "    return category_tensor, input_line_tensor, target_line_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ak17WgaN3yrU"
   },
   "source": [
    "In the next step, the model will be trained in 10,000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KW8-B3X33yy"
   },
   "outputs": [],
   "source": [
    "epochs = 100000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # Reset every plot_every iters\n",
    "#rnn = RNN(n_letters, 128, n_letters)\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, epochs + 1):\n",
    "    output, loss = train(*rand_train_exp())\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('Time: %s, Epoch: (%d - Total Iterations: %d%%),  Loss: %.4f' % (time_taken(start), iter, iter / epochs * 100, loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEH1g4qzAesz"
   },
   "source": [
    "We will visualize the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxLDhU5lAgl-"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(all_losses)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qI_zjW5mAj7y"
   },
   "source": [
    "Finally, we will sample our model to test it on generating the names belonging to languages when given a starting alphabet letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvOhaxLiAmwu"
   },
   "outputs": [],
   "source": [
    "max_length = 20\n",
    "# Sample from a category and starting letter\n",
    "def sample_model(category, start_letter='A'):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "        category_tensor = categ_Tensor(category)\n",
    "        input = inp_Tensor(start_letter)\n",
    "        hidden = model.initHidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden = model(category_tensor, input[0], hidden)\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            if topi == n_let - 1:\n",
    "                break\n",
    "            else:\n",
    "                letter = all_let[topi]\n",
    "                output_name += letter\n",
    "            input = inp_Tensor(letter)\n",
    "\n",
    "        return output_name\n",
    "\n",
    "# Get multiple samples from one category and multiple starting letters\n",
    "def sample_names(category, start_letters='XYZ'):\n",
    "    for start_letter in start_letters:\n",
    "        print(sample_model(category, start_letter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nud4RGRLApGE"
   },
   "source": [
    "Now, we will check the sampled model to generate names when given a language and the starting alphabet letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wisW8SQLAsbW"
   },
   "outputs": [],
   "source": [
    "print(\"Italian:-\")\n",
    "sample_names('Italian', 'BPRT')\n",
    "print(\"\\nKorean:-\")\n",
    "sample_names('Korean', 'CMRS')\n",
    "print(\"\\nRussian:-\")\n",
    "sample_names('Russian', 'AJLN')\n",
    "print(\"\\nVietnamese:-\")\n",
    "sample_names('Vietnamese', 'LMT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prpNOPgzWgiU"
   },
   "source": [
    "# **Related Articles:**\n",
    "\n",
    "> * [Text Generation using RNN](https://analyticsindiamag.com/recurrent-neural-network-in-pytorch-for-text-generation/)\n",
    "\n",
    "> * [SVD in Recommender System](https://analyticsindiamag.com/singular-value-decomposition-svd-application-recommender-system/)\n",
    "\n",
    "> * [TF-IDF from Scratch in Python](https://analyticsindiamag.com/hands-on-implementation-of-tf-idf-from-scratch-in-python/)\n",
    "\n",
    "> * [Continuous Bag of Words](https://analyticsindiamag.com/the-continuous-bag-of-words-cbow-model-in-nlp-hands-on-implementation-with-codes/)\n",
    "\n",
    "> * [NLP Case Study of Documents Similarity](https://analyticsindiamag.com/nlp-case-study-identify/)\n",
    "\n",
    "> * [Review Classification](https://analyticsindiamag.com/step-by-step-guide-to-reviews-classification-using-svc-naive-bayes-random-forest/)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1_RNN_for_text_generation.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
