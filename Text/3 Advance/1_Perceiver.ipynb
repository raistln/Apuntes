{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6bNhVEWr14b_"
   },
   "source": [
    "# Perceiver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1a9XE5_a161S"
   },
   "source": [
    "Perceiver is a transformer-based model that uses both cross attention and self-attention layers to generate representations of multimodal data. A latent array is used to extract information from the input byte array using top-down or feedback processing i.e. attention to a byte array is controlled by the latent array which already has information about the byte array from the previous layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BLTAGk17BX9"
   },
   "source": [
    "\n",
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHycG6z-7IQ6"
   },
   "source": [
    "## Installation\n",
    "\n",
    "A PyTorch implementation of the model was made available by authors. We can directly install this implementation from pip using the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q --no-warn-script-location\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn nltk gensim perceiver-pytorch torch tensorflow keras --user -q --no-warn-script-location\n",
    "\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzBEFFL8Vcna"
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "Letâ€™s use the CIFAR10 image dataset for training the model. Following is the boilerplate code for loading the data. The code mentioned below, is referenced to official pytorch tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iSHCQFbxQTr2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0myQ0OyiQUOb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    print(img.shape)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.shape)\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4l4pq3QyVkoO"
   },
   "source": [
    "## Model\n",
    "\n",
    "Model architecture can be loaded using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mN7PSHt3QbOq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from perceiver_pytorch import Perceiver\n",
    "\n",
    "model = Perceiver(\n",
    "    input_channels = 3,          # number of channels for each token of the input\n",
    "    input_axis = 2,              # number of axis for input data (2 for images, 3 for video)\n",
    "    num_freq_bands = 6,          # number of freq bands, with original value (2 * K + 1)\n",
    "    max_freq = 10.,              # maximum frequency, hyperparameter depending on how fine the data is\n",
    "    depth = 6,                   # depth of net\n",
    "    num_latents = 32,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
    "    latent_dim = 128,            # latent dimension\n",
    "    cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
    "    latent_heads = 2,            # number of heads for latent self attention, 8\n",
    "    cross_dim_head = 8,\n",
    "    latent_dim_head = 8,\n",
    "    num_classes = 10,          # output number of classes\n",
    "    attn_dropout = 0.,\n",
    "    ff_dropout = 0.,\n",
    "    weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ldy6jUthVo4L"
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kF2hep0lRccm"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDwsIljsWZxT"
   },
   "outputs": [],
   "source": [
    "dev=torch.device(\"cpu\")\n",
    "model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9oeXGDrAQj3i"
   },
   "outputs": [],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(dev), labels.to(dev)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs.permute(0,2,3,1))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 0:    # print every 1000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBYWAjuUCF19"
   },
   "outputs": [],
   "source": [
    "inp=inputs[0].permute(1,2,0).unsqueeze(0)\n",
    "inp=inp.to(dev)\n",
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJZU0vqnRYU6"
   },
   "outputs": [],
   "source": [
    "plt.imshow(images.permute(0,2,3,1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RY_hrIrlgQGP"
   },
   "outputs": [],
   "source": [
    "preds=model(inp)\n",
    "preds=preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWhW7o3GF5uN"
   },
   "outputs": [],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pDT610p1FWKJ"
   },
   "outputs": [],
   "source": [
    "classes[np.argmax(preds[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNcbTmSbV2Af"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQzmiLm6gwDr"
   },
   "outputs": [],
   "source": [
    "def predict(inputs):\n",
    "  preds=model(inputs)\n",
    "  preds=preds.detach().cpu().numpy()\n",
    "  labels=[classes[np.argmax(i)] for i in preds]\n",
    "  return labels\n",
    "predict(inputs.permute(0,2,3,1).to(dev))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOLZ1wH6btVUNV1Ethq8NdZ",
   "collapsed_sections": [],
   "name": "1_Perceiver.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
