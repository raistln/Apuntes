{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6w3ETtszQ2V"
   },
   "source": [
    "## **In this practice session, we will learn how to implement Recurrent Neural Networks for Sentiment Analysis**\n",
    "## **We will use imdb reviews dataset that is available in the Keras library for the implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXQdoQtl2W8s"
   },
   "source": [
    "### **Data processing**\n",
    "  *   Import the required libraries from Keras\n",
    "  *   Load the IMDB reviews dataset from Keras library\n",
    "  *   Load one instance of the review and sentiment\n",
    "  *   Pad the input data to make all input information into the same length\n",
    "\n",
    "### **Build an RNN model**\n",
    "  *   Construct a simple LSTM model \n",
    "  *   Compile the model and fit the data into the model\n",
    "  *   Evaluate the model on unseen test data\n",
    "  *   Make model predictions on test data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyyD8zH-4aF0"
   },
   "source": [
    "## **Importing the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn keras tensorflow opencv-python --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iv_Ig056m44W"
   },
   "outputs": [],
   "source": [
    "#import the required libraries for the implementation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.preprocessing import sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5p3Mjnh64d0B"
   },
   "source": [
    "## **Load the data from Keras into train and test variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Da3mdAicnvht"
   },
   "outputs": [],
   "source": [
    "#load the imdb dataset into train and test set\n",
    "from keras.datasets import imdb\n",
    "vocabulary_size = 5000\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words = vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXhvH7LD4m6Q"
   },
   "source": [
    "## **Print one instance of the review and corresponding sentiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_GILIwBqINi",
    "outputId": "b22245a6-4845-4ad1-ce50-ee27503d9b69"
   },
   "outputs": [],
   "source": [
    "#understanding how the dataset looks like\n",
    "words = imdb.get_word_index()\n",
    "\n",
    "#the words are already vectorized in the dataset, hence we reverse the process to see the word distribution\n",
    "vects = {i: word for word, i in words.items()}\n",
    "print('review')\n",
    "print([vects.get(i, ' ') for i in X_train[6]])\n",
    "\n",
    "#the sentiment is 1 if the review is positive and 0 if the review is negative\n",
    "print('sentiment')\n",
    "print(y_train[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUfJwZ4j4shL"
   },
   "source": [
    "## **Pad the data sequence to make the inputs into same length**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Od_HvaisqL_v"
   },
   "outputs": [],
   "source": [
    "#for the RNN to work all our input dependencies must have same length \n",
    "total_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=total_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPAN7UzT4yEU"
   },
   "source": [
    "## **Build a basic LSTM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JeymMMLqQlp",
    "outputId": "1aac62d9-af29-4557-e5ec-867d67124f85"
   },
   "outputs": [],
   "source": [
    "#we will build a simple LSTM model with one embedding layer, one LSTM and one output layer\n",
    "embedding_size=32\n",
    "max_words = 500\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJOZxFUh412i"
   },
   "source": [
    "## **Compile the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjFLKJRsqSJO"
   },
   "outputs": [],
   "source": [
    "#compile the model by passing the optimizer and loss function and the evaluation metric\n",
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBMcurgh44iV"
   },
   "source": [
    "## **Pass required parameters and fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kshIa4whqUSp",
    "outputId": "a56836fb-03f6-418d-b71c-88041566c732"
   },
   "outputs": [],
   "source": [
    "#fit the data to the model and begin training\n",
    "batch_size = 128\n",
    "num_epochs = 5\n",
    "x_val, y_val = X_train[:batch_size], y_train[:batch_size]\n",
    "xtrain, ytrain = X_train[batch_size:], y_train[batch_size:]\n",
    "model.fit(xtrain, ytrain, validation_data=(x_val, y_val), batch_size=batch_size, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTeBZOeV5m9Z"
   },
   "source": [
    "## **Evaluate the model on test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfuN-xZ9qWs6",
    "outputId": "9339d7ee-c98f-430f-bd53-ed8efcd55f00"
   },
   "outputs": [],
   "source": [
    "#evaluate the model accuracy on unseen test data\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ze29pbz5vGs"
   },
   "source": [
    "## **Make model predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CkdQIC9lqZ1F",
    "outputId": "ed283b5f-80f1-479c-826f-749f238efaad"
   },
   "outputs": [],
   "source": [
    "#make model predictions on test data\n",
    "# print(\"Prediction: \",model.predict_classes(X_test[1:10]))\n",
    "predict_x=model.predict(X_test[1:10]) \n",
    "classes_x=np.argmax(predict_x,axis=1)\n",
    "classes_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjuQQqINxtqf",
    "outputId": "9a96604d-39e1-4d1e-dcfc-cc9b87f81d32"
   },
   "outputs": [],
   "source": [
    "#compare the model prediction with actual data\n",
    "print(\"Actual: \",y_test[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
