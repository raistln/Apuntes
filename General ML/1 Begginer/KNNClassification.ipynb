{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this practice session, we will learn to code KNN Classifier. \n",
    "# We will perform the following steps to build a simple classifier using the popular Iris dataset.\n",
    "\n",
    " \n",
    " \n",
    "  - **Data Preprocessing**\n",
    "\n",
    "    - Importing the libraries.\n",
    "    - Importing dataset (Dataset Link https://archive.ics.uci.edu/ml/datasets/iris).\n",
    "    - Dealing with the categorical variable.\n",
    "    - Classifying dependent and independent variables.\n",
    "    - Splitting the data into a training set and test set.\n",
    "    - Feature scaling.\n",
    " \n",
    "\n",
    "  -  **KNN Classification**\n",
    "\n",
    "    - Create a KNN classifier.\n",
    "    - Feed the training data to the classifier.\n",
    "    - Predicting the species for the test set.\n",
    "    - Using the confusion matrix to find accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "style = {'description_width': 'initial'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BZ-jLOunczC"
   },
   "outputs": [],
   "source": [
    "#1 Importing essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKtERLr9n09B"
   },
   "outputs": [],
   "source": [
    "file_name = 'iris.data'\n",
    "\n",
    "#Importing dataset\n",
    "dataset = pd.read_csv(file_name, delimiter=',', names=['sepal length', 'sepal width', \\\n",
    "                                                       'petal length', \"petal width\",\n",
    "                                                      'Species'])\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset has {dataset.shape[0]} rows and {dataset.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the relation between salary and experience\n",
    "wig_col = widgets.Dropdown(\n",
    "                options=[col for col in dataset.columns.tolist() if col.startswith(('sepal', 'petal'))],\n",
    "                description='Choose a Column to Plot vs. Attributes',\n",
    "                disabled=False,\n",
    "                layout=widgets.Layout(width='40%', height='40px'),\n",
    "                style=style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(wig_col)\n",
    "\n",
    "sns.catplot(x=\"Species\", y=wig_col.value, kind=\"boxen\", data=dataset, height=8.27, aspect=11.7/8.27);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(x=\"Species\", y=wig_col.value, kind=\"violin\", inner=None, data=dataset, height=8.27, aspect=11.7/8.27)\n",
    "sns.swarmplot(x=\"Species\", y=wig_col.value, color=\"k\", size=3, data=dataset, ax=g.ax);\n",
    "\n",
    "display(wig_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5WuUWRFn4j8"
   },
   "outputs": [],
   "source": [
    "#3 classify dependent and independent variables\n",
    "X = dataset.iloc[:,:-1].values  #independent variable YearsofExperience\n",
    "y = dataset.iloc[:,-1].values  #dependent variable salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bZ82kVbn7Ga"
   },
   "outputs": [],
   "source": [
    "print(\"\\nIdependent Variable (Sepal and Petal Attributes):\\n\\n\", X[:5])\n",
    "print(\"\\nDependent Variable (Species):\\n\\n\", y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "dataset['Species'] = labelencoder.fit_transform(dataset['Species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Species'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFMIwI5Zn9MX"
   },
   "outputs": [],
   "source": [
    "#4 Creating training set and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_size = widgets.FloatSlider(min=0.01, max=0.6, value=0.2, description=\"Test Size :\", tooltips=['Usually 20-30%'])\n",
    "display(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the dataset into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X ,y, test_size=test_size.value, random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YcY06YGDn_dz"
   },
   "outputs": [],
   "source": [
    "print(\"Training Set :\\n----------------\\n\")\n",
    "print(\"X = \\n\", X_train[:5])\n",
    "print(\"y = \\n\", y_train[:5])\n",
    "\n",
    "print(\"\\n\\nTest Set :\\n----------------\\n\")\n",
    "print(\"X = \\n\",X_test[:5])\n",
    "print(\"y = \\n\", y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of Training set is {X_train.shape}\")\n",
    "print(f\"Shape of Testing set is {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalise Features\n",
    "\n",
    "As the Features are not in the range of 0-1, Let's normalize the features using Standard Scaler(Z-score) normalization and Label Encode the Class String Names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test) \n",
    "\n",
    "print(\"\\n-------------------------\\nDataset after Scaling:\\n-------------------------\\n\", )\n",
    "\n",
    "print(\"\\nX_train :\\n\", X_train[:5])\n",
    "print(\"-------------------------\")\n",
    "print(\"\\nX_test :\\n\", X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KNN library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# configure params for the model.\n",
    "algo_wig = widgets.Dropdown(options=['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
    "                             description=\"Algorithm to Compute Neighbours = \", style=style)\n",
    "\n",
    "display(algo_wig)\n",
    "\n",
    "njobs_wig = widgets.Dropdown(options=[('One', 1), ('Two', 2), ('Three', 3), ('All Cores', -1)], \n",
    "                             description=\"Number of CPU Cores = \", style=style)\n",
    "\n",
    "display(njobs_wig)\n",
    "\n",
    "neigh_wig = widgets.Dropdown(options=[1, 10, 30, 100], \n",
    "                             description=\"Number of Neighbours = \", style=style)\n",
    "\n",
    "display(neigh_wig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Evaluate the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XbYFyk8oCrH"
   },
   "outputs": [],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=neigh_wig.value, algorithm=algo_wig.value,\n",
    "                                  n_jobs=njobs_wig.value)\n",
    "\n",
    "#Feed the training data to the classifier\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "#Predicting the species for test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(\"\\n---------------------------\\n\")\n",
    "print(\"Predicted Values for Test Set :\\n\",y_pred)\n",
    "print(\"\\n---------------------------\\n\")\n",
    "print(\"Actual Values for Test Set :\\n\",y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAwiJVWuoHEX"
   },
   "outputs": [],
   "source": [
    "#8 Claculating the Accuracy of the predictions\n",
    "from sklearn import metrics\n",
    "print(\"Prediction Accuracy = \", metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "#9 Comparing Actual and Predicted Salaries for he test set\n",
    "print(\"\\nActual vs Predicted Salaries \\n------------------------------\\n\")\n",
    "error_df = pd.DataFrame({\"Actual\" : y_test,\n",
    "                         \"Predicted\" : y_pred})\n",
    "\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual vs. Predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using confusion matrix to find the accuracy\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "accuracy = cm.diagonal().sum()/cm.sum()\n",
    "\n",
    "print(\"\\n---------------------------\\n\")\n",
    "print(\"Accuracy of Predictions = \",accuracy)\n",
    "\n",
    "print(\"\\n---------------------------\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LinearRegression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
