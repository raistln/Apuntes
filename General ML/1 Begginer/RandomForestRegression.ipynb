{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this practice session, we will learn to code Random Forest Regression. \n",
    "# We will perform the following steps to build a simple classifier using the popular Iris dataset.\n",
    "\n",
    " \n",
    " \n",
    "  - **Data Preprocessing**\n",
    "\n",
    "    - Importing the libraries.\n",
    "    - Importing dataset (Dataset Link https://archive.ics.uci.edu/ml/datasets/iris).\n",
    "    - Dealing with the categorical variable.\n",
    "    - Classifying dependent and independent variables.\n",
    "    - Splitting the data into a training set and test set.\n",
    "    - Feature scaling.\n",
    " \n",
    "\n",
    "  -  **Random Forest Regression**\n",
    "\n",
    "    - Create a Random Forest Regressor.\n",
    "    - Feed the training data to the regression model.\n",
    "    - Predicting the species for the test set.\n",
    "    - Using the RMSE to calculate the error metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q\n",
    "!python -m pip install numpy pandas seaborn matplotlib scipy statsmodels sklearn --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "style = {'description_width': 'initial'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BZ-jLOunczC"
   },
   "outputs": [],
   "source": [
    "#1 Importing essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKtERLr9n09B"
   },
   "outputs": [],
   "source": [
    "#2 Importing the dataset\n",
    "\n",
    "file_name = 'beer_data.csv'\n",
    "dataset = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the dataset\n",
    "dataset.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset has {dataset.shape[0]} rows and {dataset.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Nulls and Fill Nulls Based on Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check nulls..\n",
    "\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[~dataset['Cellar Temperature'].isna()]\n",
    "dataset.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ABV'].fillna(dataset['ABV'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with the categorical data\n",
    "\n",
    "# Spliting Cellar Temperature into Maximum and Minimum based on the given data and converting the type from str to int\n",
    "\n",
    "dataset.loc[:, 'Minimum_Cellar_Temp'] = dataset['Cellar Temperature'].apply(lambda x : int(str(x).split('-')[0].strip()))\n",
    "dataset.loc[:, 'Maximum_Cellar_Temp'] = dataset['Cellar Temperature'].apply(lambda x : int(str(x).split('-')[1].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop('Cellar Temperature', inplace=True, axis=1)\n",
    "dataset.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5WuUWRFn4j8"
   },
   "outputs": [],
   "source": [
    "# classify dependent and independent variables\n",
    "X = dataset[[col for col in dataset.columns if col not in ('Score')]].values  #independent variables \n",
    "y = dataset['Score'].values  #dependent variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bZ82kVbn7Ga"
   },
   "outputs": [],
   "source": [
    "print(\"\\nIdependent Variables :\\n\\n\", X[:5])\n",
    "print(\"\\nDependent Variable (Score):\\n\\n\", y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFMIwI5Zn9MX"
   },
   "outputs": [],
   "source": [
    "#4 Creating training set and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_size = widgets.FloatSlider(min=0.01, max=0.6, value=0.2, description=\"Test Size :\", tooltips=['Usually 20-30%'])\n",
    "display(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the dataset into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X ,y, test_size=test_size.value, random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YcY06YGDn_dz"
   },
   "outputs": [],
   "source": [
    "print(\"Training Set :\\n----------------\\n\")\n",
    "print(\"X = \\n\", X_train[:5])\n",
    "print(\"y = \\n\", y_train[:5])\n",
    "\n",
    "print(\"\\n\\nTest Set :\\n----------------\\n\")\n",
    "print(\"X = \\n\",X_test[:5])\n",
    "print(\"y = \\n\", y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of Training set is {X_train.shape}\")\n",
    "print(f\"Shape of Testing set is {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Random Forest Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random forest library\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# configure params for the model.\n",
    "max_feat_wig = widgets.ToggleButtons(options=['log2', 'sqrt', 'auto'],\n",
    "                                    description='Number of features for the best split :',\n",
    "                                    disabled=False,\n",
    "                                    style=style)\n",
    "\n",
    "display(max_feat_wig)\n",
    "\n",
    "max_depth_wig = widgets.Dropdown(options=[10, 20, 30, 50],\n",
    "                            description='The maximum depth of the Tree. :',\n",
    "                            style=style)\n",
    "\n",
    "display(max_depth_wig)\n",
    "\n",
    "min_split_wig = widgets.Dropdown(options=[100, 200, 300, 500],\n",
    "                            description='Minimum Number of Splits. :',\n",
    "                            style=style)\n",
    "\n",
    "display(min_split_wig)\n",
    "\n",
    "njobs_wig = widgets.Dropdown(options=[('One', 1), ('Two', 2), ('Three', 3), ('All Cores', -1)], \n",
    "                             description=\"Number of CPU Cores :\", style=style)\n",
    "\n",
    "display(njobs_wig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Evaluate the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XbYFyk8oCrH"
   },
   "outputs": [],
   "source": [
    "# Train the Regressor with training set\n",
    "regressor = RandomForestRegressor(max_features=max_feat_wig.value,\n",
    "                                  max_depth=max_depth_wig.value,\n",
    "                                  min_samples_split=min_split_wig.value,\n",
    "                                  n_jobs=njobs_wig.value)\n",
    "\n",
    "#fit the linear model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "#7 predict the outcome of test sets\n",
    "y_Pred = regressor.predict(X_test)\n",
    "print(\"\\nPredictions = \", y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAwiJVWuoHEX",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculating score from Root Mean Log Squared Error\n",
    "def rmlse(y_test, y_pred):\n",
    "    error = np.square(np.log10(y_pred +1) - np.log10(y_test +1)).mean() ** 0.5\n",
    "    score = 1 - error\n",
    "    return score\n",
    "\n",
    "# Printing the score\n",
    "print(\"\\n----------------------------\\nRMLSE Score = \", rmlse(y_test, y_Pred))\n",
    "\n",
    "#9 Comparing Actual and Predicted Salaries for he test set\n",
    "print(\"\\nActual vs Predicted Scores \\n------------------------------\\n\")\n",
    "error_df = pd.DataFrame({\"Actual\" : y_test,\n",
    "                         \"Predicted\" : y_Pred,\n",
    "                         \"Abs. Error\" : np.abs(y_test - y_Pred)})\n",
    "\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = [col for col in dataset.columns if col not in ('Score')]\n",
    "\n",
    "pd.Series(regressor.feature_importances_, \\\n",
    "          index=feat_names).sort_values(ascending=True).plot(kind='barh', figsize=(16,9));\n",
    "\n",
    "plt.title('Feature Importance Random Forest Regressor');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual vs. Predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Actual observation vs Predictions\n",
    "plt.figure(figsize=(16, 9));\n",
    "plt.scatter(y_test, y_Pred, s = 70)\n",
    "plt.xlabel('Actual');\n",
    "plt.ylabel('Predicted');\n",
    "plt.grid();\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LinearRegression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
