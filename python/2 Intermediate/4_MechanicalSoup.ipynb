{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7GQzQn4olsv"
   },
   "source": [
    "# MechanicalSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTVhpB00oqQ5"
   },
   "source": [
    "MechanicalSoup is a python package that automatically stores and sends cookies, follows redirects, and also can follow hyperlinks and forms in a webpage. It was created by M Hickford. He was always amazed by the Mechanize library. Mechanize was a John J. Lee project which enables programmatic web browsing in Python, and it was later taken over by Kovid Goyal in 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SHTwZUYorHc"
   },
   "source": [
    "To read about it more, please refer [this](https://analyticsindiamag.com/mechanicalsoup-web-scraping-custom-dataset-tutorial/) article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQl_lGj2paZk"
   },
   "source": [
    "# Code Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFDU7ZdGpeQK"
   },
   "source": [
    "You can install MechanicalSoup using PyPI (python package manager).\n",
    "\n",
    "Mechanical soup install command will download BeautifulSoup, requests, six, Urllib, and other libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x_nP6zPdojOz"
   },
   "outputs": [],
   "source": [
    "!python -m pip install pip --upgrade --user -q\n",
    "!python -m pip install MechanicalSoup wget --user -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RR0KQB9Dpyct"
   },
   "source": [
    "## Quickstart\n",
    "\n",
    "Testing our library for any errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EL3-3BVApw9X"
   },
   "outputs": [],
   "source": [
    "import mechanicalsoup\n",
    "\n",
    "browser = mechanicalsoup.StatefulBrowser()\n",
    "url = \"http://httpbin.org/\"\n",
    "\n",
    "browser.open(url)\n",
    "print(browser.get_url())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8JRl5Lyp5TD"
   },
   "source": [
    "Furthermore, we can do some other things with MechanicalSoup like following the subdomains as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kG4fNRRqp20J"
   },
   "outputs": [],
   "source": [
    "browser.follow_link(\"forms\")\n",
    "browser.get_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5vy3Asgp_5r"
   },
   "source": [
    "Now we are on a new domain http://httpbin.org/forms/post, Let’s extract the page content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fKjnoXj_p-U1"
   },
   "outputs": [],
   "source": [
    "browser.get_current_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObhaB2IBqDLL"
   },
   "source": [
    "You can find any tag by using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2jIGKd8RqBZ_"
   },
   "outputs": [],
   "source": [
    "browser.get_current_page().find_all('legend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHN-irrVqH8G"
   },
   "source": [
    "We  can also fill the forms and POST request using MechanicalSoup by using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNr4pHIPqFaw"
   },
   "outputs": [],
   "source": [
    "browser.select_form('form[action=\"/post\"]')\n",
    "browser.get_current_form().print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_F-MrEbqWzt"
   },
   "source": [
    "For filling the form we can use the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yIokZkXqWtt"
   },
   "outputs": [],
   "source": [
    "browser[\"custname\"] = \"Mohit\"\n",
    "browser[\"custtel\"] = \"9081515151\"\n",
    "browser[\"custemail\"] = \"mohitmaithani@aol.com\"\n",
    "browser[\"comments\"] = \"please make pizza dough more soft\"\n",
    "browser[\"size\"] = \"large\"\n",
    "browser[\"topping\"] = \"mushroom\"\n",
    " \n",
    "#launch browser\n",
    "browser.launch_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeNu1N3MqdAv"
   },
   "source": [
    "## Let’s scrape Cats’ images from the internet using MechanicalSoup and create our custom dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwEgy2fzqjLL"
   },
   "source": [
    "It’s a good use-case. The very first step of every data science project is to create or collect data, and then further processing, cleaning, analysis, modeling, and tuning part comes. Now, as we already familiar with essential API, let’s straight jump to code:\n",
    "\n",
    "> * Search cats on Google Images\n",
    "\n",
    "We are setting the google search query and making it open in the browser with search text cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWDOJDihqUat"
   },
   "outputs": [],
   "source": [
    "import mechanicalsoup\n",
    " \n",
    "browser = mechanicalsoup.StatefulBrowser()\n",
    "url = \"https://www.google.com/imghp?hl=en\"\n",
    " \n",
    "browser.open(url)\n",
    " \n",
    "#get HTML\n",
    "browser.get_current_page()\n",
    " \n",
    "#target the search input\n",
    "browser.select_form()\n",
    "browser.get_current_form().print_summary()\n",
    " \n",
    "#search for a term\n",
    "search_term = 'cat'\n",
    "browser[\"q\"] = search_term \n",
    " \n",
    "#submit/\"click\" search\n",
    "browser.launch_browser()\n",
    "response = browser.submit_selected()\n",
    " \n",
    "print('new url:', browser.get_url())\n",
    "print('response:\\n', response.text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTw5UZpwqrE2"
   },
   "source": [
    "Navigate to the new pages and target all the images, it will return the output as URLs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jMqn7ieqogq"
   },
   "outputs": [],
   "source": [
    "#open URL\n",
    "new_url = browser.get_url()\n",
    "browser.open(new_url)\n",
    "\n",
    "#get HTML code\n",
    "page = browser.get_current_page()\n",
    "all_images = page.find_all('img')\n",
    "\n",
    "#target the source attributes of image\n",
    "image_source = []\n",
    "for image in all_images:\n",
    "    image = image.get('src')\n",
    "    image_source.append(image)\n",
    "\n",
    "image_source[5:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ix9SqQruqvRY"
   },
   "source": [
    "Let’s fix the corrupted URLs\n",
    "\n",
    "Python startswith function to filter the URLs not having HTTPS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-vt4pBhqtox"
   },
   "outputs": [],
   "source": [
    "#save cleaned links in \"image_source\"\n",
    "image_source = [image for image in image_source if image.startswith('https')]\n",
    "\n",
    "print(image_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QXNLf2Xq1Li"
   },
   "source": [
    "Create a local repo to store cat images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment to save it in the local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IV9KWZP6q1Wn"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    " \n",
    "# path = os.getcwd()\n",
    "# path = os.path.join(path, search_term + \"s\")\n",
    " \n",
    "# #create the directory\n",
    "# os.mkdir(path)\n",
    "# #print path where cats images are going to save\n",
    "# path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKVboE81q4B6"
   },
   "source": [
    "\n",
    "Download using wget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6RikVvzVq5sp"
   },
   "outputs": [],
   "source": [
    "import wget  \n",
    "\n",
    "##download images\n",
    "counter = 0\n",
    "for image in image_source:\n",
    "    save_as = os.path.join(path, search_term + str(counter) + '.jpg')\n",
    "    wget.download(image, save_as)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zL3OnQvGq8F7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPPKOnr8F+KOH1YOi642dtA",
   "collapsed_sections": [],
   "name": "4_MechanicalSoup.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "f60a20abaabf5a658075b37fac599269792a9493ddacd7c14d8505185d5625aa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
